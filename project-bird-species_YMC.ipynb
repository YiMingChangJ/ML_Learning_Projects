{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN and Transfer Learning with PyTorch: 200 Bird Species Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a project written in the framework of the Online live course Deep Learning with PyTorch: Zero to GANs, delivered by Jovian.ml in collaboration with FreeCodeCamp.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training using Convolutional Neural Network (CNN) and Transfer Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project considers the 200 Bird Species image dataset in order to develop a classification model using Convolutional Neural Network and transfer learning with Pytorch.\n",
    "\n",
    "The dataset is from kaggle under the name 200 Bird Species. As the name indicates, the dataset contains images of 200 species of birds from different regions around the world. The images are in JPEG format with size 3x224x224. The dataset has 27,503 images for training, 1,000 images for validation et 1,000 images for testing.\n",
    "\n",
    "The objective of this project is to train a model with CNN and transfer learning in order to be able to get a good accuracy, a minimum loss and to have a very good prediction of the different bird species images.\n",
    "We will use the training dataset to train the model, the validation dataset to evaluate the model while training and the test dataset to test the model using external data.\n",
    "\n",
    "We start by importing the libraries and the datasets that we need for this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the libraries and the datasets that we need for this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'C://Users//Yi Ming Chang//Desktop//Dal//PHYC 4250 Topics in Numerical Computing//Problem Sets//Problem set 5//bird species'\n",
    "\n",
    "TRAIN_DIR = DATA_DIR + '/train'\n",
    "VALID_DIR = DATA_DIR + '/valid'\n",
    "TEST_DIR = DATA_DIR + '/test'                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='project-bird-species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36609, 1300, 1300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = ImageFolder(TRAIN_DIR)\n",
    "valid_data = ImageFolder(VALID_DIR)\n",
    "test_data = ImageFolder(TEST_DIR)\n",
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data exploration and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said in the beginning, the dataset has 200 bird species meaning that we have 200 different classes or 200 outputs we would like to predict with the trained model. These are the classes we have in the train dataset and we have the same set of classes in the validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFRICAN CROWNED CRANE',\n",
       " 'AFRICAN FIREFINCH',\n",
       " 'ALBATROSS',\n",
       " 'ALEXANDRINE PARAKEET',\n",
       " 'AMERICAN AVOCET',\n",
       " 'AMERICAN BITTERN',\n",
       " 'AMERICAN COOT',\n",
       " 'AMERICAN GOLDFINCH',\n",
       " 'AMERICAN KESTREL',\n",
       " 'AMERICAN PIPIT',\n",
       " 'AMERICAN REDSTART',\n",
       " 'ANHINGA',\n",
       " 'ANNAS HUMMINGBIRD',\n",
       " 'ANTBIRD',\n",
       " 'ARARIPE MANAKIN',\n",
       " 'ASIAN CRESTED IBIS',\n",
       " 'BALD EAGLE',\n",
       " 'BALI STARLING',\n",
       " 'BALTIMORE ORIOLE',\n",
       " 'BANANAQUIT',\n",
       " 'BANDED BROADBILL',\n",
       " 'BAR-TAILED GODWIT',\n",
       " 'BARN OWL',\n",
       " 'BARN SWALLOW',\n",
       " 'BARRED PUFFBIRD',\n",
       " 'BAY-BREASTED WARBLER',\n",
       " 'BEARDED BARBET',\n",
       " 'BELTED KINGFISHER',\n",
       " 'BIRD OF PARADISE',\n",
       " 'BLACK FRANCOLIN',\n",
       " 'BLACK SKIMMER',\n",
       " 'BLACK SWAN',\n",
       " 'BLACK TAIL CRAKE',\n",
       " 'BLACK THROATED WARBLER',\n",
       " 'BLACK VULTURE',\n",
       " 'BLACK-CAPPED CHICKADEE',\n",
       " 'BLACK-NECKED GREBE',\n",
       " 'BLACK-THROATED SPARROW',\n",
       " 'BLACKBURNIAM WARBLER',\n",
       " 'BLUE GROUSE',\n",
       " 'BLUE HERON',\n",
       " 'BOBOLINK',\n",
       " 'BROWN NOODY',\n",
       " 'BROWN THRASHER',\n",
       " 'CACTUS WREN',\n",
       " 'CALIFORNIA CONDOR',\n",
       " 'CALIFORNIA GULL',\n",
       " 'CALIFORNIA QUAIL',\n",
       " 'CANARY',\n",
       " 'CAPE MAY WARBLER',\n",
       " 'CAPUCHINBIRD',\n",
       " 'CARMINE BEE-EATER',\n",
       " 'CASPIAN TERN',\n",
       " 'CASSOWARY',\n",
       " 'CHARA DE COLLAR',\n",
       " 'CHIPPING SPARROW',\n",
       " 'CHUKAR PARTRIDGE',\n",
       " 'CINNAMON TEAL',\n",
       " 'COCK OF THE  ROCK',\n",
       " 'COCKATOO',\n",
       " 'COMMON FIRECREST',\n",
       " 'COMMON GRACKLE',\n",
       " 'COMMON HOUSE MARTIN',\n",
       " 'COMMON LOON',\n",
       " 'COMMON POORWILL',\n",
       " 'COMMON STARLING',\n",
       " 'COUCHS KINGBIRD',\n",
       " 'CRESTED AUKLET',\n",
       " 'CRESTED CARACARA',\n",
       " 'CRESTED NUTHATCH',\n",
       " 'CROW',\n",
       " 'CROWNED PIGEON',\n",
       " 'CUBAN TODY',\n",
       " 'CURL CRESTED ARACURI',\n",
       " 'D-ARNAUDS BARBET',\n",
       " 'DARK EYED JUNCO',\n",
       " 'DOWNY WOODPECKER',\n",
       " 'EASTERN BLUEBIRD',\n",
       " 'EASTERN MEADOWLARK',\n",
       " 'EASTERN ROSELLA',\n",
       " 'EASTERN TOWEE',\n",
       " 'ELEGANT TROGON',\n",
       " 'ELLIOTS  PHEASANT',\n",
       " 'EMPEROR PENGUIN',\n",
       " 'EMU',\n",
       " 'ENGGANO MYNA',\n",
       " 'EURASIAN GOLDEN ORIOLE',\n",
       " 'EURASIAN MAGPIE',\n",
       " 'EVENING GROSBEAK',\n",
       " 'FIRE TAILLED MYZORNIS',\n",
       " 'FLAME TANAGER',\n",
       " 'FLAMINGO',\n",
       " 'FRIGATE',\n",
       " 'GAMBELS QUAIL',\n",
       " 'GANG GANG COCKATOO',\n",
       " 'GILA WOODPECKER',\n",
       " 'GILDED FLICKER',\n",
       " 'GLOSSY IBIS',\n",
       " 'GO AWAY BIRD',\n",
       " 'GOLD WING WARBLER',\n",
       " 'GOLDEN CHEEKED WARBLER',\n",
       " 'GOLDEN CHLOROPHONIA',\n",
       " 'GOLDEN EAGLE',\n",
       " 'GOLDEN PHEASANT',\n",
       " 'GOLDEN PIPIT',\n",
       " 'GOULDIAN FINCH',\n",
       " 'GRAY CATBIRD',\n",
       " 'GRAY PARTRIDGE',\n",
       " 'GREAT POTOO',\n",
       " 'GREATOR SAGE GROUSE',\n",
       " 'GREEN JAY',\n",
       " 'GREY PLOVER',\n",
       " 'GUINEA TURACO',\n",
       " 'GUINEAFOWL',\n",
       " 'GYRFALCON',\n",
       " 'HARPY EAGLE',\n",
       " 'HAWAIIAN GOOSE',\n",
       " 'HELMET VANGA',\n",
       " 'HIMALAYAN MONAL',\n",
       " 'HOATZIN',\n",
       " 'HOODED MERGANSER',\n",
       " 'HOOPOES',\n",
       " 'HORNBILL',\n",
       " 'HORNED GUAN',\n",
       " 'HORNED SUNGEM',\n",
       " 'HOUSE FINCH',\n",
       " 'HOUSE SPARROW',\n",
       " 'IMPERIAL SHAQ',\n",
       " 'INCA TERN',\n",
       " 'INDIAN BUSTARD',\n",
       " 'INDIAN PITTA',\n",
       " 'INDIGO BUNTING',\n",
       " 'JABIRU',\n",
       " 'JAVA SPARROW',\n",
       " 'JAVAN MAGPIE',\n",
       " 'KAKAPO',\n",
       " 'KILLDEAR',\n",
       " 'KING VULTURE',\n",
       " 'KIWI',\n",
       " 'KOOKABURRA',\n",
       " 'LARK BUNTING',\n",
       " 'LEARS MACAW',\n",
       " 'LILAC ROLLER',\n",
       " 'LONG-EARED OWL',\n",
       " 'MAGPIE GOOSE',\n",
       " 'MALABAR HORNBILL',\n",
       " 'MALACHITE KINGFISHER',\n",
       " 'MALEO',\n",
       " 'MALLARD DUCK',\n",
       " 'MANDRIN DUCK',\n",
       " 'MARABOU STORK',\n",
       " 'MASKED BOOBY',\n",
       " 'MASKED LAPWING',\n",
       " 'MIKADO  PHEASANT',\n",
       " 'MOURNING DOVE',\n",
       " 'MYNA',\n",
       " 'NICOBAR PIGEON',\n",
       " 'NOISY FRIARBIRD',\n",
       " 'NORTHERN BALD IBIS',\n",
       " 'NORTHERN CARDINAL',\n",
       " 'NORTHERN FLICKER',\n",
       " 'NORTHERN GANNET',\n",
       " 'NORTHERN GOSHAWK',\n",
       " 'NORTHERN JACANA',\n",
       " 'NORTHERN MOCKINGBIRD',\n",
       " 'NORTHERN PARULA',\n",
       " 'NORTHERN RED BISHOP',\n",
       " 'NORTHERN SHOVELER',\n",
       " 'OCELLATED TURKEY',\n",
       " 'OKINAWA RAIL',\n",
       " 'OSPREY',\n",
       " 'OSTRICH',\n",
       " 'OYSTER CATCHER',\n",
       " 'PAINTED BUNTIG',\n",
       " 'PALILA',\n",
       " 'PARADISE TANAGER',\n",
       " 'PARUS MAJOR',\n",
       " 'PEACOCK',\n",
       " 'PELICAN',\n",
       " 'PEREGRINE FALCON',\n",
       " 'PHILIPPINE EAGLE',\n",
       " 'PINK ROBIN',\n",
       " 'PUFFIN',\n",
       " 'PURPLE FINCH',\n",
       " 'PURPLE GALLINULE',\n",
       " 'PURPLE MARTIN',\n",
       " 'PURPLE SWAMPHEN',\n",
       " 'QUETZAL',\n",
       " 'RAINBOW LORIKEET',\n",
       " 'RAZORBILL',\n",
       " 'RED BEARDED BEE EATER',\n",
       " 'RED BELLIED PITTA',\n",
       " 'RED FACED CORMORANT',\n",
       " 'RED FACED WARBLER',\n",
       " 'RED HEADED DUCK',\n",
       " 'RED HEADED WOODPECKER',\n",
       " 'RED HONEY CREEPER',\n",
       " 'RED TAILED THRUSH',\n",
       " 'RED WINGED BLACKBIRD',\n",
       " 'RED WISKERED BULBUL',\n",
       " 'REGENT BOWERBIRD',\n",
       " 'RING-NECKED PHEASANT',\n",
       " 'ROADRUNNER',\n",
       " 'ROBIN',\n",
       " 'ROCK DOVE',\n",
       " 'ROSY FACED LOVEBIRD',\n",
       " 'ROUGH LEG BUZZARD',\n",
       " 'RUBY THROATED HUMMINGBIRD',\n",
       " 'RUFOUS KINGFISHER',\n",
       " 'RUFUOS MOTMOT',\n",
       " 'SAMATRAN THRUSH',\n",
       " 'SAND MARTIN',\n",
       " 'SCARLET IBIS',\n",
       " 'SCARLET MACAW',\n",
       " 'SHOEBILL',\n",
       " 'SHORT BILLED DOWITCHER',\n",
       " 'SMITHS LONGSPUR',\n",
       " 'SNOWY EGRET',\n",
       " 'SNOWY OWL',\n",
       " 'SORA',\n",
       " 'SPANGLED COTINGA',\n",
       " 'SPLENDID WREN',\n",
       " 'SPOON BILED SANDPIPER',\n",
       " 'SPOONBILL',\n",
       " 'SRI LANKA BLUE MAGPIE',\n",
       " 'STEAMER DUCK',\n",
       " 'STORK BILLED KINGFISHER',\n",
       " 'STRAWBERRY FINCH',\n",
       " 'STRIPPED SWALLOW',\n",
       " 'SUPERB STARLING',\n",
       " 'SWINHOES PHEASANT',\n",
       " 'TAIWAN MAGPIE',\n",
       " 'TAKAHE',\n",
       " 'TASMANIAN HEN',\n",
       " 'TEAL DUCK',\n",
       " 'TIT MOUSE',\n",
       " 'TOUCHAN',\n",
       " 'TOWNSENDS WARBLER',\n",
       " 'TREE SWALLOW',\n",
       " 'TRUMPTER SWAN',\n",
       " 'TURKEY VULTURE',\n",
       " 'TURQUOISE MOTMOT',\n",
       " 'UMBRELLA BIRD',\n",
       " 'VARIED THRUSH',\n",
       " 'VENEZUELIAN TROUPIAL',\n",
       " 'VERMILION FLYCATHER',\n",
       " 'VICTORIA CROWNED PIGEON',\n",
       " 'VIOLET GREEN SWALLOW',\n",
       " 'VULTURINE GUINEAFOWL',\n",
       " 'WATTLED CURASSOW',\n",
       " 'WHIMBREL',\n",
       " 'WHITE CHEEKED TURACO',\n",
       " 'WHITE NECKED RAVEN',\n",
       " 'WHITE TAILED TROPIC',\n",
       " 'WILD TURKEY',\n",
       " 'WILSONS BIRD OF PARADISE',\n",
       " 'WOOD DUCK',\n",
       " 'YELLOW BELLIED FLOWERPECKER',\n",
       " 'YELLOW CACIQUE',\n",
       " 'YELLOW HEADED BLACKBIRD']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES = list(train_data.class_to_idx.keys())\n",
    "CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we count the number of images we have in each dataset according the different species. For the validation and test dataset, we have 5 images for each class while for the training dataset, the number of images may be different according each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'AFRICAN CROWNED CRANE': 137,\n",
       "         'AFRICAN FIREFINCH': 140,\n",
       "         'ALBATROSS': 133,\n",
       "         'ALEXANDRINE PARAKEET': 165,\n",
       "         'AMERICAN AVOCET': 179,\n",
       "         'AMERICAN BITTERN': 170,\n",
       "         'AMERICAN COOT': 158,\n",
       "         'AMERICAN GOLDFINCH': 133,\n",
       "         'AMERICAN KESTREL': 130,\n",
       "         'AMERICAN PIPIT': 179,\n",
       "         'AMERICAN REDSTART': 139,\n",
       "         'ANHINGA': 147,\n",
       "         'ANNAS HUMMINGBIRD': 139,\n",
       "         'ANTBIRD': 150,\n",
       "         'ARARIPE MANAKIN': 105,\n",
       "         'ASIAN CRESTED IBIS': 105,\n",
       "         'BALD EAGLE': 160,\n",
       "         'BALI STARLING': 132,\n",
       "         'BALTIMORE ORIOLE': 137,\n",
       "         'BANANAQUIT': 106,\n",
       "         'BANDED BROADBILL': 194,\n",
       "         'BAR-TAILED GODWIT': 114,\n",
       "         'BARN OWL': 119,\n",
       "         'BARN SWALLOW': 132,\n",
       "         'BARRED PUFFBIRD': 136,\n",
       "         'BAY-BREASTED WARBLER': 143,\n",
       "         'BEARDED BARBET': 160,\n",
       "         'BELTED KINGFISHER': 125,\n",
       "         'BIRD OF PARADISE': 104,\n",
       "         'BLACK FRANCOLIN': 131,\n",
       "         'BLACK SKIMMER': 111,\n",
       "         'BLACK SWAN': 112,\n",
       "         'BLACK TAIL CRAKE': 149,\n",
       "         'BLACK THROATED WARBLER': 135,\n",
       "         'BLACK VULTURE': 126,\n",
       "         'BLACK-CAPPED CHICKADEE': 133,\n",
       "         'BLACK-NECKED GREBE': 105,\n",
       "         'BLACK-THROATED SPARROW': 168,\n",
       "         'BLACKBURNIAM WARBLER': 134,\n",
       "         'BLUE GROUSE': 185,\n",
       "         'BLUE HERON': 104,\n",
       "         'BOBOLINK': 157,\n",
       "         'BROWN NOODY': 129,\n",
       "         'BROWN THRASHER': 99,\n",
       "         'CACTUS WREN': 122,\n",
       "         'CALIFORNIA CONDOR': 153,\n",
       "         'CALIFORNIA GULL': 109,\n",
       "         'CALIFORNIA QUAIL': 115,\n",
       "         'CANARY': 160,\n",
       "         'CAPE MAY WARBLER': 145,\n",
       "         'CAPUCHINBIRD': 133,\n",
       "         'CARMINE BEE-EATER': 121,\n",
       "         'CASPIAN TERN': 213,\n",
       "         'CASSOWARY': 114,\n",
       "         'CHARA DE COLLAR': 104,\n",
       "         'CHIPPING SPARROW': 115,\n",
       "         'CHUKAR PARTRIDGE': 168,\n",
       "         'CINNAMON TEAL': 117,\n",
       "         'COCK OF THE  ROCK': 124,\n",
       "         'COCKATOO': 166,\n",
       "         'COMMON FIRECREST': 139,\n",
       "         'COMMON GRACKLE': 177,\n",
       "         'COMMON HOUSE MARTIN': 127,\n",
       "         'COMMON LOON': 109,\n",
       "         'COMMON POORWILL': 161,\n",
       "         'COMMON STARLING': 141,\n",
       "         'COUCHS KINGBIRD': 140,\n",
       "         'CRESTED AUKLET': 106,\n",
       "         'CRESTED CARACARA': 146,\n",
       "         'CRESTED NUTHATCH': 163,\n",
       "         'CROW': 107,\n",
       "         'CROWNED PIGEON': 118,\n",
       "         'CUBAN TODY': 122,\n",
       "         'CURL CRESTED ARACURI': 137,\n",
       "         'D-ARNAUDS BARBET': 233,\n",
       "         'DARK EYED JUNCO': 203,\n",
       "         'DOWNY WOODPECKER': 127,\n",
       "         'EASTERN BLUEBIRD': 128,\n",
       "         'EASTERN MEADOWLARK': 190,\n",
       "         'EASTERN ROSELLA': 118,\n",
       "         'EASTERN TOWEE': 127,\n",
       "         'ELEGANT TROGON': 144,\n",
       "         'ELLIOTS  PHEASANT': 148,\n",
       "         'EMPEROR PENGUIN': 129,\n",
       "         'EMU': 106,\n",
       "         'ENGGANO MYNA': 124,\n",
       "         'EURASIAN GOLDEN ORIOLE': 135,\n",
       "         'EURASIAN MAGPIE': 155,\n",
       "         'EVENING GROSBEAK': 144,\n",
       "         'FIRE TAILLED MYZORNIS': 150,\n",
       "         'FLAME TANAGER': 177,\n",
       "         'FLAMINGO': 122,\n",
       "         'FRIGATE': 105,\n",
       "         'GAMBELS QUAIL': 147,\n",
       "         'GANG GANG COCKATOO': 142,\n",
       "         'GILA WOODPECKER': 146,\n",
       "         'GILDED FLICKER': 138,\n",
       "         'GLOSSY IBIS': 175,\n",
       "         'GO AWAY BIRD': 131,\n",
       "         'GOLD WING WARBLER': 128,\n",
       "         'GOLDEN CHEEKED WARBLER': 176,\n",
       "         'GOLDEN CHLOROPHONIA': 135,\n",
       "         'GOLDEN EAGLE': 123,\n",
       "         'GOLDEN PHEASANT': 107,\n",
       "         'GOLDEN PIPIT': 113,\n",
       "         'GOULDIAN FINCH': 130,\n",
       "         'GRAY CATBIRD': 155,\n",
       "         'GRAY PARTRIDGE': 103,\n",
       "         'GREAT POTOO': 138,\n",
       "         'GREATOR SAGE GROUSE': 184,\n",
       "         'GREEN JAY': 156,\n",
       "         'GREY PLOVER': 120,\n",
       "         'GUINEA TURACO': 162,\n",
       "         'GUINEAFOWL': 104,\n",
       "         'GYRFALCON': 124,\n",
       "         'HARPY EAGLE': 175,\n",
       "         'HAWAIIAN GOOSE': 113,\n",
       "         'HELMET VANGA': 107,\n",
       "         'HIMALAYAN MONAL': 151,\n",
       "         'HOATZIN': 155,\n",
       "         'HOODED MERGANSER': 135,\n",
       "         'HOOPOES': 125,\n",
       "         'HORNBILL': 122,\n",
       "         'HORNED GUAN': 113,\n",
       "         'HORNED SUNGEM': 126,\n",
       "         'HOUSE FINCH': 249,\n",
       "         'HOUSE SPARROW': 125,\n",
       "         'IMPERIAL SHAQ': 144,\n",
       "         'INCA TERN': 118,\n",
       "         'INDIAN BUSTARD': 131,\n",
       "         'INDIAN PITTA': 186,\n",
       "         'INDIGO BUNTING': 147,\n",
       "         'JABIRU': 143,\n",
       "         'JAVA SPARROW': 122,\n",
       "         'JAVAN MAGPIE': 109,\n",
       "         'KAKAPO': 130,\n",
       "         'KILLDEAR': 175,\n",
       "         'KING VULTURE': 136,\n",
       "         'KIWI': 138,\n",
       "         'KOOKABURRA': 143,\n",
       "         'LARK BUNTING': 117,\n",
       "         'LEARS MACAW': 131,\n",
       "         'LILAC ROLLER': 138,\n",
       "         'LONG-EARED OWL': 106,\n",
       "         'MAGPIE GOOSE': 142,\n",
       "         'MALABAR HORNBILL': 130,\n",
       "         'MALACHITE KINGFISHER': 163,\n",
       "         'MALEO': 120,\n",
       "         'MALLARD DUCK': 135,\n",
       "         'MANDRIN DUCK': 130,\n",
       "         'MARABOU STORK': 197,\n",
       "         'MASKED BOOBY': 132,\n",
       "         'MASKED LAPWING': 131,\n",
       "         'MIKADO  PHEASANT': 146,\n",
       "         'MOURNING DOVE': 126,\n",
       "         'MYNA': 141,\n",
       "         'NICOBAR PIGEON': 129,\n",
       "         'NOISY FRIARBIRD': 157,\n",
       "         'NORTHERN BALD IBIS': 128,\n",
       "         'NORTHERN CARDINAL': 130,\n",
       "         'NORTHERN FLICKER': 139,\n",
       "         'NORTHERN GANNET': 145,\n",
       "         'NORTHERN GOSHAWK': 112,\n",
       "         'NORTHERN JACANA': 156,\n",
       "         'NORTHERN MOCKINGBIRD': 140,\n",
       "         'NORTHERN PARULA': 196,\n",
       "         'NORTHERN RED BISHOP': 135,\n",
       "         'NORTHERN SHOVELER': 130,\n",
       "         'OCELLATED TURKEY': 118,\n",
       "         'OKINAWA RAIL': 107,\n",
       "         'OSPREY': 127,\n",
       "         'OSTRICH': 123,\n",
       "         'OYSTER CATCHER': 207,\n",
       "         'PAINTED BUNTIG': 163,\n",
       "         'PALILA': 119,\n",
       "         'PARADISE TANAGER': 176,\n",
       "         'PARUS MAJOR': 122,\n",
       "         'PEACOCK': 156,\n",
       "         'PELICAN': 118,\n",
       "         'PEREGRINE FALCON': 126,\n",
       "         'PHILIPPINE EAGLE': 154,\n",
       "         'PINK ROBIN': 128,\n",
       "         'PUFFIN': 124,\n",
       "         'PURPLE FINCH': 128,\n",
       "         'PURPLE GALLINULE': 128,\n",
       "         'PURPLE MARTIN': 109,\n",
       "         'PURPLE SWAMPHEN': 154,\n",
       "         'QUETZAL': 152,\n",
       "         'RAINBOW LORIKEET': 141,\n",
       "         'RAZORBILL': 194,\n",
       "         'RED BEARDED BEE EATER': 197,\n",
       "         'RED BELLIED PITTA': 151,\n",
       "         'RED FACED CORMORANT': 127,\n",
       "         'RED FACED WARBLER': 167,\n",
       "         'RED HEADED DUCK': 103,\n",
       "         'RED HEADED WOODPECKER': 133,\n",
       "         'RED HONEY CREEPER': 132,\n",
       "         'RED TAILED THRUSH': 130,\n",
       "         'RED WINGED BLACKBIRD': 127,\n",
       "         'RED WISKERED BULBUL': 123,\n",
       "         'REGENT BOWERBIRD': 123,\n",
       "         'RING-NECKED PHEASANT': 97,\n",
       "         'ROADRUNNER': 107,\n",
       "         'ROBIN': 95,\n",
       "         'ROCK DOVE': 132,\n",
       "         'ROSY FACED LOVEBIRD': 139,\n",
       "         'ROUGH LEG BUZZARD': 127,\n",
       "         'RUBY THROATED HUMMINGBIRD': 135,\n",
       "         'RUFOUS KINGFISHER': 156,\n",
       "         'RUFUOS MOTMOT': 189,\n",
       "         'SAMATRAN THRUSH': 128,\n",
       "         'SAND MARTIN': 95,\n",
       "         'SCARLET IBIS': 138,\n",
       "         'SCARLET MACAW': 105,\n",
       "         'SHOEBILL': 175,\n",
       "         'SHORT BILLED DOWITCHER': 164,\n",
       "         'SMITHS LONGSPUR': 116,\n",
       "         'SNOWY EGRET': 132,\n",
       "         'SNOWY OWL': 161,\n",
       "         'SORA': 300,\n",
       "         'SPANGLED COTINGA': 112,\n",
       "         'SPLENDID WREN': 121,\n",
       "         'SPOON BILED SANDPIPER': 144,\n",
       "         'SPOONBILL': 192,\n",
       "         'SRI LANKA BLUE MAGPIE': 161,\n",
       "         'STEAMER DUCK': 109,\n",
       "         'STORK BILLED KINGFISHER': 135,\n",
       "         'STRAWBERRY FINCH': 167,\n",
       "         'STRIPPED SWALLOW': 120,\n",
       "         'SUPERB STARLING': 144,\n",
       "         'SWINHOES PHEASANT': 217,\n",
       "         'TAIWAN MAGPIE': 136,\n",
       "         'TAKAHE': 108,\n",
       "         'TASMANIAN HEN': 135,\n",
       "         'TEAL DUCK': 159,\n",
       "         'TIT MOUSE': 146,\n",
       "         'TOUCHAN': 136,\n",
       "         'TOWNSENDS WARBLER': 165,\n",
       "         'TREE SWALLOW': 181,\n",
       "         'TRUMPTER SWAN': 137,\n",
       "         'TURKEY VULTURE': 149,\n",
       "         'TURQUOISE MOTMOT': 156,\n",
       "         'UMBRELLA BIRD': 144,\n",
       "         'VARIED THRUSH': 193,\n",
       "         'VENEZUELIAN TROUPIAL': 127,\n",
       "         'VERMILION FLYCATHER': 155,\n",
       "         'VICTORIA CROWNED PIGEON': 146,\n",
       "         'VIOLET GREEN SWALLOW': 201,\n",
       "         'VULTURINE GUINEAFOWL': 169,\n",
       "         'WATTLED CURASSOW': 138,\n",
       "         'WHIMBREL': 138,\n",
       "         'WHITE CHEEKED TURACO': 153,\n",
       "         'WHITE NECKED RAVEN': 112,\n",
       "         'WHITE TAILED TROPIC': 175,\n",
       "         'WILD TURKEY': 144,\n",
       "         'WILSONS BIRD OF PARADISE': 126,\n",
       "         'WOOD DUCK': 214,\n",
       "         'YELLOW BELLIED FLOWERPECKER': 129,\n",
       "         'YELLOW CACIQUE': 155,\n",
       "         'YELLOW HEADED BLACKBIRD': 159})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "img_counter = Counter([train_data.classes[labels] for _,labels in train_data])\n",
    "img_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the characteristic of a single image we have in the dataset. As we can see, the image has size 224x224 with three channels (RGB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we display few images of the birds we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_images = ImageFolder(TRAIN_DIR, transform=T.Compose([T.ToTensor()]))\n",
    "set_images_dl = DataLoader(set_images, 60 , shuffle=True, \n",
    "                      num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl, invert=True):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        data = 1-images if invert else images\n",
    "        ax.imshow(make_grid(data, nrow=10).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(set_images_dl, invert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we start preparing the data for the training by making some transformations on them.\n",
    "\n",
    "Pytorch has some utilities to make randomized data augmentation and channel-wise normalization. These two transformations permit to transform the image data in order to end up with a better performance of the model. Before to be able to make the transformations, we have first to transform the images to tensors as PyTorch knows only to work with tensors. \n",
    " \n",
    " Channel-wise normalization permits to normalize an image tensor by subtracting the mean and by dividing by the standard deviation of each dimension. In this case, ours tensors will have three dimensions as we have three channels (red, blue and green).\n",
    " \n",
    "Randomized data augmentation helps to avoid over fitting by cropping and flipping the image horizontally (if we choose that option of flipping). This will permit also a better generalization of the model.\n",
    "We apply the randomized data augmentation and channel-wise normalization to the training dataset. For validation and test datasets, we do only normalization.\n",
    "\n",
    "To normalize the image channels, we consider the means and the standard deviations from the ImageNet database considering this as a part of transfer learning.\n",
    "\n",
    "Below we have the transformations that we considered. Many other types of transformations are available on the PyTorch website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.RandomCrop(224, padding=8, padding_mode='reflect'),\n",
    "    T.RandomHorizontalFlip(), \n",
    "    T.RandomRotation(10),\n",
    "    T.ToTensor(), \n",
    "    T.Normalize(*imagenet_stats,inplace=True), \n",
    "    T.RandomErasing(inplace=True)\n",
    "])\n",
    "\n",
    "valid_tfms = T.Compose([ \n",
    "    T.ToTensor(), \n",
    "    T.Normalize(*imagenet_stats)\n",
    "])\n",
    "\n",
    "test_tfms = T.Compose([ \n",
    "    T.ToTensor(), \n",
    "    T.Normalize(*imagenet_stats)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the transformations to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(TRAIN_DIR, train_tfms)\n",
    "val_ds = ImageFolder(VALID_DIR, valid_tfms)\n",
    "test_ds = ImageFolder(TEST_DIR, test_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have the shape of a single transformed image tensor for which the label is 0. As we have 200 classes, they will be labeled from 0 to 199."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) 0\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = train_ds[0]\n",
    "print(img_tensor.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of classes we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.classes)             #Number of classes in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training data and the model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this training, we consider a batch size of 256. As we run this model on kaggle kernel, we have enough memory space and a GPU as accelerator that permits the training to go faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define our data loader which will load the data in batches of 256 image tensors during each epoch of training. We consider twice batch size for validation data loader. This is because we do not make any gradient calculation during the validation step, so we will have enough memory space to consider more data.\n",
    "\n",
    "We shuffle the loading only for the training dataset. We do not need to do that for validation and test datasets as there is no need for randomization in these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, \n",
    "                      num_workers=2, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, \n",
    "                    num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present here a set of images based on the transformed data. We can see the difference with the images we have previously which are from the original dataset. We can remark the effect of cropping and the horizontal flipping on the different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl, invert=True):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        data = 1-images if invert else images\n",
    "        ax.imshow(make_grid(images[:60], nrow=10).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(train_dl, invert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We develop here our base model for the training (training step and validation step). We consider as metrics accuracy and loss. To determine the losses of the model, we use the cross entropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using transfer learning, we consider as a starting point the pretrained model resnet34 which is a model trained on the ImageNet database. This permits to benefit from its learning on millions of high-resolution images. We have below the architecture of resnet34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34 = models.resnet34()\n",
    "#resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extend our base classification model with the pretrained model resnet34.\n",
    "\n",
    "Also, we define two interesting function, freeze and unfreeze. Freeze permits to freeze the weights and biases of the previous layers (from resnet34, before fc) during the training, and we have changes only on the weights and biases of the last layer (fc). This allows the weights and biases to be trained first (as the weights and biases from resnet34 have already been trained) and after few epochs we unfreeze the weights and biases to make the training on the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdResnet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet34(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, len(train_ds.classes))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return torch.sigmoid(self.network(xb))\n",
    "    \n",
    "    def freeze(self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = False\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad = True\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define here a function will permit us to move our data and model to the device. The device we are using is GPU. In case GPU is not available, the function will move the data to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "#device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data to the default device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of considering a fixed learning rate for the training, we will use what is called a learning rate scheduling. With this strategy, the learning rate will vary after each epoch of training. max_lr is the maximum value of the learning rate we consider. Learning rate scheduling is a useful function provided by PyTorch allowing us to automatically consider different learning rate during the training process.\n",
    "\n",
    "We record also the losses from the validation steps and the used learning rates from each epoch. As recommended in the literature, we do a cycle with equal lengths, one going from a small value of learning rate to the maximum value, and another one from the maximum to a minimum value of the learning rate.\n",
    "\n",
    "To have control on the weights and the gradients and to avoid that they become too large, we are using also weight decay and gradient clipping. These help also in a better generalization of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we transfer the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(BirdResnet(), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the training start, we begin to evaluate the model. This evaluation shows the starting point of the metrics (loss and accuracy). As we can, we have a loss of 5.30 and a very low accuracy of 0.005. The objective is to minimize the loss and maximize the accuracy while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 5.572378635406494, 'val_acc': 0.001953125}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(model, val_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start training the model, we first freeze the previous layers of the model as we mentioned previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define here the values of the different hyperparameters. We choose to make 15 epochs in the freezing step and 15 after we unfreezed the model meaning that in total we have 30 epochs. We consider a maximum learning rate of 0.001 (we found this value better than the others we have tested), gradient clipping value of 1 and a weight decay of 1e-5. The gradient clipping of 1 means that the gradients will be kept in a range of -1 and 1. Also, we use Adam as optimization function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model takes hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "max_lr = 0.01\n",
    "grad_clip = 1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we start training the model. We can see how the loss and the accuracy change over the different epochs of the training. Starting with 0.005 accuracy, we jump to 0.7987 after the first epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c29c06ca614ec38fbeca50d3374562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,  \n",
    "                         opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we unfreeze the model to train it on the entire architecture. At this step, we found it better in term of accuracy to consider a value of max_lr as 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history += fit_one_cycle(epochs, 0.0001, model, train_dl, val_dl, \n",
    "                         grad_clip=grad_clip, \n",
    "                         weight_decay=weight_decay,\n",
    "                         opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time='41mn:12s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As graphs may be more informative, we plot the history of the loss and the accuracy during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows clearly how the accuracy increases very fast but slowdown its increasing after a certain number of epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see also that the training loss and validation loss are going together. This means that we avoided over fitting in our training. We have to be careful in choosing the number of epoch because the model may start over fitting if this number becomes too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lrs(history):\n",
    "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
    "    plt.plot(lrs)\n",
    "    plt.xlabel('Batch no.')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.title('Learning Rate vs. Batch no.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the history of the considered learning rates during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lrs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we trained the model, let's make few predictions and assess its performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    xb = to_device(xb, device)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can, the model predict the different species of birds pretty well. We can see that by comparing the predicted label of the species and their actual label. These ones are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Final evaluation of the trained model on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate our model on the test dataset and ended up with a loss of 4.31 and an accuracy rate of 96 percent which is a good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds, batch_size*2, \n",
    "                    num_workers=2, pin_memory=True)\n",
    "\n",
    "test_dl = DeviceDataLoader(test_dl, device)\n",
    "result = evaluate(model, test_dl)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we can say that our model predict very well the different species of birds. \n",
    "\n",
    "As a future work about this dataset, we will try to use Generative Adversarial Networks to develop a model which will permit to generate a set of birds images.\n",
    "\n",
    "This course was an amazing journey through which we learned many things. As the name of the course indicates, we went from zero to GANS. We have learned how to make machine learning by using linear and logistic regressions, deep learning with feed forward neural network, deep learning with convolutional neural network and GANS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://neurohive.io/en/popular-networks/resnet/\n",
    "https://sgugger.github.io/the-1cycle-policy.html\n",
    "https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab\n",
    "https://www.youtube.com/watch?v=sJF6PiAjE1M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.linkedin.com/in/moustapha-daouda-dala/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
