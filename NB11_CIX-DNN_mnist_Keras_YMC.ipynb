{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 11: Introduction to Deep Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "The goal of this notebook is to introduce deep neural networks (DNNs) using the high-level Keras package. The reader will become familiar with how to choose an architecture, cost function, and optimizer in Keras. We will also learn how to train neural networks.\n",
    "\n",
    "\n",
    "# MNIST with Keras\n",
    "\n",
    "We will once again work with the MNIST dataset of hand written digits introduced in *Notebook 7: Logistic Regression (MNIST)*. The goal is to find a statistical model which recognizes and distinguishes between the ten handwritten digits (0-9).\n",
    "\n",
    "The MNIST dataset comprises $70000$ handwritten digits, each of which comes in a square image, divided into a $28\\times 28$ pixel grid. Every pixel can take on $256$ nuances of the gray color, interpolating between white and black, and hence each data point assumes any value in the set $\\{0,1,\\dots,255\\}$. Since there are $10$ categories in the problem, corresponding to the ten digits, this problem represents a generic classification task. \n",
    "\n",
    "In this Notebook, we show how to use the Keras python package to tackle the MNIST problem with the help of deep neural networks.\n",
    "\n",
    "The following code is a slight modification of a Keras tutorial, see [https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py). We invite the reader to read Sec. IX of the review to acquire a broad understanding of what the separate parts of the code do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras,sklearn\n",
    "# suppress tensorflow compilation warnings\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Procedure\n",
    "\n",
    "Constructing a Deep Neural Network to solve ML problems is a multiple-stage process. Quite generally, one can identify the key steps as follows:\n",
    "\n",
    "* ***step 1:*** Load and process the data\n",
    "* ***step 2:*** Define the model and its architecture\n",
    "* ***step 3:*** Choose the optimizer and the cost function\n",
    "* ***step 4:*** Train the model \n",
    "* ***step 5:*** Evaluate the model performance on the *unseen* test data\n",
    "* ***step 6:*** Modify the hyperparameters to optimize performance for the specific data set\n",
    "\n",
    "We would like to emphasize that, while it is always possible to view steps 1-5 as independent of the particular task we are trying to solve, it is only when they are put together in ***step 6*** that the real gain of using Deep Learning is revealed, compared to less sophisticated methods such as the regression models or bagging, described in Secs. VII and VIII of the review. With this remark in mind, we shall focus predominantly on steps 1-5 below. We show how one can use grid search methods to find optimal hyperparameters in ***step 6***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Process the Data\n",
    "\n",
    "Keras can conveniently download the MNIST data from the web. All we need to do is import the `mnist` module and use the `load_data()` class, and it will create the training and test data sets or us.\n",
    "\n",
    "The MNIST set has pre-defined test and training sets, in order to facilitate the comparison of the performance of different models on the data.\n",
    "\n",
    "Once we have loaded the data, we need to format it in the correct shape. This differs from one package to the other and, as we see in the case of Keras, it can even be different depending on the backend used.\n",
    "\n",
    "While choosing the correct `datatype` can help improve the computational speed, we emphasize the rescaling step, which is necessary to avoid large variations in the minimal and maximal possible values of each feature. In other words, we want to make sure a feature is not being over-represented just because it is \"large\".\n",
    "\n",
    "Last, we cast the label vectors $y$ to binary class matrices (a.k.a. one-hot format), as explained in Sec. VII on SoftMax regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "an example of a data point with label 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAGkCAYAAACckEpMAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGqVJREFUeJzt3W1sU+cZxvHL5cUFlrhQmtgZaZRR0FBhTAUWQC0v1YjIVMRLp1GqTYm0oTJeJBZQtRRthFUiHRuoH1i7lW0MNBhsGqVIoEIqSADRdIBSgVjF0hFGEEkzELUDZY4ozz5EuHUToMfYuWPn/5OOio/PnXPz6Kkvnvj42OeccwIAwNAD1g0AAEAYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMylVRi99tprKiws1IMPPqhx48bpyJEj1i11q8rKSvl8vrgtGAxat9UtDh8+rFmzZikvL08+n0+7d++Oe945p8rKSuXl5WnAgAGaNm2azpw5Y9NsCt1rHMrKyjrNkYkTJ9o0m0JVVVWaMGGCsrKylJOTozlz5ujs2bNxx/SGOfFlxiFd5kTahNHOnTu1fPlyrVq1SvX19XrqqadUUlKiCxcuWLfWrR5//HE1NzfHttOnT1u31C2uX7+usWPHauPGjV0+v27dOm3YsEEbN27U8ePHFQwGNWPGDLW1tXVzp6l1r3GQpJkzZ8bNkX379nVjh92jtrZWS5YsUV1dnaqrq3Xz5k0VFxfr+vXrsWN6w5z4MuMgpcmccGniW9/6llu0aFHcvq9//evupz/9qVFH3W/16tVu7Nix1m2Yk+TefPPN2ONbt265YDDoXnnlldi+//3vfy4QCLjf/va3Bh12jy+Og3POlZaWutmzZ5v0Y6m1tdVJcrW1tc653jsnvjgOzqXPnEiLlVF7e7tOnjyp4uLiuP3FxcU6duyYUVc2GhoalJeXp8LCQj333HM6d+6cdUvmGhsb1dLSEjc//H6/pk6d2uvmhyTV1NQoJydHI0eO1MKFC9Xa2mrdUsqFw2FJ0pAhQyT13jnxxXG4LR3mRFqE0eXLl/Xpp58qNzc3bn9ubq5aWlqMuup+RUVF2rp1q/bv369NmzappaVFkydP1pUrV6xbM3V7DvT2+SFJJSUl2rZtmw4ePKj169fr+PHjevrppxWNRq1bSxnnnMrLy/Xkk09q9OjRknrnnOhqHKT0mRN9rRvwwufzxT12znXal8lKSkpifx4zZowmTZqk4cOHa8uWLSovLzfsrGfo7fNDkubPnx/78+jRozV+/HgVFBRo7969mjdvnmFnqbN06VKdOnVKR48e7fRcb5oTdxqHdJkTabEyGjp0qPr06dPpXzStra2d/uXTmwwaNEhjxoxRQ0ODdSumbl9RyPzoLBQKqaCgIGPnyLJly7Rnzx4dOnRIw4YNi+3vbXPiTuPQlZ46J9IijPr3769x48apuro6bn91dbUmT55s1JW9aDSqDz74QKFQyLoVU4WFhQoGg3Hzo729XbW1tb16fkjSlStX1NTUlHFzxDmnpUuXateuXTp48KAKCwvjnu8tc+Je49CVHjsnDC+e8GTHjh2uX79+7g9/+IP75z//6ZYvX+4GDRrkzp8/b91at1mxYoWrqalx586dc3V1de6ZZ55xWVlZvWIM2traXH19vauvr3eS3IYNG1x9fb37z3/+45xz7pVXXnGBQMDt2rXLnT592i1YsMCFQiEXiUSMO0+uu41DW1ubW7FihTt27JhrbGx0hw4dcpMmTXJf/epXM24cfvzjH7tAIOBqampcc3NzbPvkk09ix/SGOXGvcUinOZE2YeScc7/5zW9cQUGB69+/v3viiSfiLl/sDebPn+9CoZDr16+fy8vLc/PmzXNnzpyxbqtbHDp0yEnqtJWWljrnOi7lXb16tQsGg87v97spU6a406dP2zadAncbh08++cQVFxe7Rx55xPXr1889+uijrrS01F24cMG67aTragwkuc2bN8eO6Q1z4l7jkE5zwuecc923DgMAoLO0eM8IAJDZCCMAgDnCCABgjjACAJgjjAAA5ggjAIC5tAqjaDSqysrKHneDPwuMRQfGoQPj8BnGokO6jUNafc4oEokoEAgoHA4rOzvbuh1TjEUHxqED4/AZxqJDuo1DWq2MAACZiTACAJjrcd9ndOvWLV26dElZWVmdvnckEonE/bc3Yyw6MA4dGIfPMBYdesI4OOfU1tamvLw8PfDA3dc+Pe49o4sXLyo/P9+6DQBAkjQ1Nd3ze5Z63MooKytLUkfz6fCmGwCga5FIRPn5+bHX9bvpcWF0+1dz2dnZhBEAZIAv81XvKbuA4bXXXlNhYaEefPBBjRs3TkeOHEnVqQAAaS4lYbRz504tX75cq1atUn19vZ566imVlJTowoULqTgdACDNpeQChqKiIj3xxBN6/fXXY/tGjRqlOXPmqKqq6q616fZBLQBA17y8nid9ZdTe3q6TJ0+quLg4bn9xcbGOHTvW6fhoNKpIJBK3AQB6l6SH0eXLl/Xpp58qNzc3bn9ubq5aWlo6HV9VVaVAIBDbuKwbAHqflF3A8MWrJ5xzXV5RUVFRoXA4HNuamppS1RIAoIdK+qXdQ4cOVZ8+fTqtglpbWzutliTJ7/fL7/cnuw0AQBpJ+sqof//+GjdunKqrq+P2V1dXa/Lkyck+HQAgA6TkQ6/l5eX6wQ9+oPHjx2vSpEl64403dOHCBS1atCgVpwMApLmUhNH8+fN15coV/eIXv1Bzc7NGjx6tffv2qaCgIBWnAwCkuR53o1Q+ZwQAmcH0c0YAAHhFGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzfa0bANAz/etf//Jcs2jRIs8127Zt81wjSaFQKKE69EysjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJjjRqkJaGtr81xz7do1zzWBQMBzjSQNHDgwoTrg8/bt2+e5pra21nPN73//e881klRRUeG5pm9fXvJ6KlZGAABzhBEAwFzSw6iyslI+ny9uCwaDyT4NACCDpOQXqI8//rjeeeed2OM+ffqk4jQAgAyRkjDq27cvqyEAwJeWkveMGhoalJeXp8LCQj333HM6d+7cHY+NRqOKRCJxGwCgd0l6GBUVFWnr1q3av3+/Nm3apJaWFk2ePFlXrlzp8viqqioFAoHYlp+fn+yWAAA9XNLDqKSkRM8++6zGjBmjb3/729q7d68kacuWLV0eX1FRoXA4HNuampqS3RIAoIdL+SfABg0apDFjxqihoaHL5/1+v/x+f6rbAAD0YCn/nFE0GtUHH3ygUCiU6lMBANJU0sNo5cqVqq2tVWNjo9577z1997vfVSQSUWlpabJPBQDIEEn/Nd3Fixe1YMECXb58WY888ogmTpyouro6FRQUJPtUAIAMkfQw2rFjR7J/JAAgw3EL2wT88pe/9FxTVVXluebXv/615xpJ+slPfpJQHfB548aN65bzVFZWJlS3YMECzzWPPfZYQudC6nGjVACAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOa4UWoPtmbNmoTqvva1r3mumT17dkLnQub66KOPrFtAL8LKCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDlulNqDtbW1JVRXVlbmuaa6utpzzfjx4z3XwMa1a9c816xfvz4FnSTPX//6V881L730Ugo6QTKwMgIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmOOu3QkoLCy0buGuIpGI55qf//znnmu2bdvmuUaSBg8enFAdEtfQ0OC55h//+EcKOgG6xsoIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOW6UmoCysjLPNZcuXfJcU1lZ6bkmUfv37/dc8/e//z2hc/3oRz9KqA6Jy83N9VwzfPhwzzX//ve/Pdck6nvf+163nQupx8oIAGCOMAIAmPMcRocPH9asWbOUl5cnn8+n3bt3xz3vnFNlZaXy8vI0YMAATZs2TWfOnElWvwCADOQ5jK5fv66xY8dq48aNXT6/bt06bdiwQRs3btTx48cVDAY1Y8YMtbW13XezAIDM5PkChpKSEpWUlHT5nHNOr776qlatWqV58+ZJkrZs2aLc3Fxt375dL7zwwv11CwDISEl9z6ixsVEtLS0qLi6O7fP7/Zo6daqOHTvWZU00GlUkEonbAAC9S1LDqKWlRVLny0hzc3Njz31RVVWVAoFAbMvPz09mSwCANJCSq+l8Pl/cY+dcp323VVRUKBwOx7ampqZUtAQA6MGS+qHXYDAoqWOFFAqFYvtbW1vv+KE7v98vv9+fzDYAAGkmqSujwsJCBYNBVVdXx/a1t7ertrZWkydPTuapAAAZxPPK6Nq1a/rwww9jjxsbG/X+++9ryJAhevTRR7V8+XKtXbtWI0aM0IgRI7R27VoNHDhQzz//fFIbBwBkDs9hdOLECU2fPj32uLy8XJJUWlqqP/3pT3rxxRd148YNLV68WFevXlVRUZEOHDigrKys5HUNAMgoPuecs27i8yKRiAKBgMLhsLKzs63bSZpwOOy5pqioKKFzNTQ0JFTn1Te+8Y2E6t555x3PNQ8//HBC50KH+vp6zzXjx49PQSfJc/bsWc81jz32WAo6wZ14eT3n3nQAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMJfXL9XBngUDAc02i3wHVXTdKPXXqVEJ1iXybb0+/UWp7e7vnmt/97ncp6KRrf/vb37rtXEAiWBkBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMxx1+4eLNG7dm/ZsiXJnSTXu+++67nmm9/8pueaY8eOdUuNJF27ds1zzcsvv5zQuTLNqFGjEqobPHhwkjuBJVZGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzPmcc866ic+LRCIKBAIKh8PKzs62bictff/73/dcs3379hR00nsk8r+Rz+dLQSe9x6ZNmzzX/PCHP0xBJ7gTL6/nrIwAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCY62vdAJJvxYoVnmv+8pe/pKAT3A03Sr0/dXV1nmu4UWrPxcoIAGCOMAIAmPMcRocPH9asWbOUl5cnn8+n3bt3xz1fVlYmn88Xt02cODFZ/QIAMpDnMLp+/brGjh2rjRs33vGYmTNnqrm5Obbt27fvvpoEAGQ2zxcwlJSUqKSk5K7H+P1+BYPBhJsCAPQuKXnPqKamRjk5ORo5cqQWLlyo1tbWOx4bjUYViUTiNgBA75L0MCopKdG2bdt08OBBrV+/XsePH9fTTz+taDTa5fFVVVUKBAKxLT8/P9ktAQB6uKR/zmj+/PmxP48ePVrjx49XQUGB9u7dq3nz5nU6vqKiQuXl5bHHkUiEQAKAXiblH3oNhUIqKChQQ0NDl8/7/X75/f5UtwEA6MFS/jmjK1euqKmpSaFQKNWnAgCkKc8ro2vXrunDDz+MPW5sbNT777+vIUOGaMiQIaqsrNSzzz6rUCik8+fP66WXXtLQoUM1d+7cpDYOAMgcnsPoxIkTmj59euzx7fd7SktL9frrr+v06dPaunWrPv74Y4VCIU2fPl07d+5UVlZW8roGAGQUz2E0bdo0Oefu+Pz+/fvvqyEAQO/DXbuBJBgxYoTnmkTu2v2d73zHc40kPfTQQ55r1qxZk9C5gERwo1QAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmuFEq0sLDDz/suSaRr69fuXKl5xpJWrBgQUJ13aW+vt5zDTdKRXdiZQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcN0rNQMOHD/dcU1pa6rnm3LlznmskadSoUZ5rFi9e7LlmzJgxnmuQPg4cOOC55urVq55rBg8e7LkG3rEyAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4bpWag7OxszzV//OMfU9AJkDoXL170XNPe3p6CTpAMrIwAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOa4azfQCzz00EOea0KhkOea5uZmzzXdqaKiwnPNG2+8kdC5+vbl5dULVkYAAHOEEQDAnKcwqqqq0oQJE5SVlaWcnBzNmTNHZ8+ejTvGOafKykrl5eVpwIABmjZtms6cOZPUpgEAmcVTGNXW1mrJkiWqq6tTdXW1bt68qeLiYl2/fj12zLp167RhwwZt3LhRx48fVzAY1IwZM9TW1pb05gEAmcHTO2xvv/123OPNmzcrJydHJ0+e1JQpU+Sc06uvvqpVq1Zp3rx5kqQtW7YoNzdX27dv1wsvvNDpZ0ajUUWj0djjSCSSyN8DAJDG7us9o3A4LEkaMmSIJKmxsVEtLS0qLi6OHeP3+zV16lQdO3asy59RVVWlQCAQ2/Lz8++nJQBAGko4jJxzKi8v15NPPqnRo0dLklpaWiRJubm5ccfm5ubGnvuiiooKhcPh2NbU1JRoSwCANJXwhfBLly7VqVOndPTo0U7P+Xy+uMfOuU77bvP7/fL7/Ym2AQDIAAmtjJYtW6Y9e/bo0KFDGjZsWGx/MBiUpE6roNbW1k6rJQAAbvMURs45LV26VLt27dLBgwdVWFgY93xhYaGCwaCqq6tj+9rb21VbW6vJkycnp2MAQMbx9Gu6JUuWaPv27XrrrbeUlZUVWwEFAgENGDBAPp9Py5cv19q1azVixAiNGDFCa9eu1cCBA/X888+n5C8AAEh/nsLo9ddflyRNmzYtbv/mzZtVVlYmSXrxxRd148YNLV68WFevXlVRUZEOHDigrKyspDQMAMg8Puecs27i8yKRiAKBgMLhsLKzs63bAXqt9957z3PN3LlzPdd89NFHnmu6U6KffRw0aFCSO0k/Xl7PuTcdAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAcwl/0yuAzFZUVOS55q233vJcM2vWLM81kvTf//43oTqvTpw4kVDd1KlTk9xJZmNlBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwx127ASTNhAkTPNds2LAhoXP96le/8lzzzDPPeK4ZP3685xp4x8oIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOZ9zzlk38XmRSESBQEDhcFjZ2dnW7QAAEuTl9ZyVEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzHkKo6qqKk2YMEFZWVnKycnRnDlzdPbs2bhjysrK5PP54raJEycmtWkAQGbxFEa1tbVasmSJ6urqVF1drZs3b6q4uFjXr1+PO27mzJlqbm6Obfv27Utq0wCAzNLXy8Fvv/123OPNmzcrJydHJ0+e1JQpU2L7/X6/gsFgcjoEAGS8+3rPKBwOS5KGDBkSt7+mpkY5OTkaOXKkFi5cqNbW1jv+jGg0qkgkErcBAHoXn3POJVLonNPs2bN19epVHTlyJLZ/586d+spXvqKCggI1NjbqZz/7mW7evKmTJ0/K7/d3+jmVlZVas2ZNp/1f5jvTAQA9VyQSUSAQ+FKv5wmH0ZIlS7R3714dPXpUw4YNu+Nxzc3NKigo0I4dOzRv3rxOz0ejUUWj0bjm8/PzCSMASHNewsjTe0a3LVu2THv27NHhw4fvGkSSFAqFVFBQoIaGhi6f9/v9Xa6YAAC9h6cwcs5p2bJlevPNN1VTU6PCwsJ71ly5ckVNTU0KhUIJNwkAyGyeLmBYsmSJ/vznP2v79u3KyspSS0uLWlpadOPGDUnStWvXtHLlSr377rs6f/68ampqNGvWLA0dOlRz585NyV8AAJD+PL1n5PP5uty/efNmlZWV6caNG5ozZ47q6+v18ccfKxQKafr06Xr55ZeVn5//pc7h5XeMAICeK2XvGd0rtwYMGKD9+/d7+ZEAAHBvOgCAPcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAub7WDXyRc06SFIlEjDsBANyP26/jt1/X76bHhVFbW5skKT8/37gTAEAytLW1KRAI3PUYn/sykdWNbt26pUuXLikrK0s+ny/uuUgkovz8fDU1NSk7O9uow56BsejAOHRgHD7DWHToCePgnFNbW5vy8vL0wAN3f1eox62MHnjgAQ0bNuyux2RnZ/fqSfZ5jEUHxqED4/AZxqKD9Tjca0V0GxcwAADMEUYAAHNpFUZ+v1+rV6+W3++3bsUcY9GBcejAOHyGseiQbuPQ4y5gAAD0Pmm1MgIAZCbCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOb+DwnyoFFdOL2vAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "# reshape data, depending on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "    \n",
    "# cast floats to single precesion\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[20])\n",
    "plt.matshow(X_train[20,:].reshape(28,28),cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Neural Net and its Architecture\n",
    "\n",
    "We can now move on to construct our deep neural net. We shall use Keras's `Sequential()` class to instantiate a model, and will add different deep layers one by one.\n",
    "\n",
    "At this stage, we refrain from using convolutional layers. This is done further below.\n",
    "\n",
    "Let us create an instance of Keras' `Sequential()` class, called `model`. As the name suggests, this class allows us to build DNNs layer by layer. We use the `add()` method to attach layers to our model. For the purposes of our introductory example, it suffices to focus on `Dense` layers for simplicity. Every `Dense()` layer accepts as its first required argument an integer which specifies the number of neurons. The type of activation function for the layer is defined using the `activation` optional argument, the input of which is the name of the activation function in `string` format. Examples include `relu`, `tanh`, `elu`, `sigmoid`, `softmax`. \n",
    "\n",
    "In order for our DNN to work properly, we have to make sure that the numbers of input and output neurons for each layer match. Therefore, we specify the shape of the input in the first layer of the model explicitly using the optional argument `input_shape=(N_features,)`. The sequential construction of the model then allows Keras to infer the correct input/output dimensions of all hidden layers automatically. Hence, we only need to specify the size of the softmax output layer to match the number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture created successfully!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(400,input_shape=(img_rows*img_cols,), activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose the Optimizer and the Cost Function\n",
    "\n",
    "Next, we choose the loss function according to which to train the DNN. For classification problems, this is the cross entropy, and since the output data was cast in categorical form, we choose the `categorical_crossentropy` defined in Keras' `losses` module. Depending on the problem of interest one can pick any other suitable loss function. To optimize the weights of the net, we choose SGD. This algorithm is already available to use under Keras' `optimizers` module, but we could use `Adam()` or any other built-in one as well. The parameters for the optimizer, such as `lr` (learning rate) or `momentum` are passed using the corresponding optional arguments of the `SGD()` function. All available arguments can be found in Keras' online documentation at [https://keras.io/](https://keras.io/). While the loss function and the optimizer are essential for the training procedure, to test the performance of the model one may want to look at a particular `metric` of performance. For instance, in categorical tasks one typically looks at their `accuracy`, which is defined as the percentage of correctly classified data points. To complete the definition of our model, we use the `compile()` method, with optional arguments for the `optimizer`, `loss`, and the validation `metric` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully and ready to be trained.\n"
     ]
    }
   ],
   "source": [
    "def compile_model(optimizer=keras.optimizers.Adam()):\n",
    "    # create the mode\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model\n",
    "\n",
    "We train our DNN in minibatches, the advantages of which were explained in Sec. IV. \n",
    "\n",
    "Shuffling the training data during training improves stability of the model. Thus, we train over a number of training epochs. \n",
    "\n",
    "Training the DNN is a one-liner using the `fit()` method of the `Sequential` class. The first two required arguments are the training input and output data. As optional arguments, we specify the mini-`batch_size`, the number of training `epochs`, and the test or `validation_data`. To monitor the training procedure for every epoch, we set `verbose=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.3156 - accuracy: 0.9078 - val_loss: 0.1137 - val_accuracy: 0.9647\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1257 - accuracy: 0.9640 - val_loss: 0.0886 - val_accuracy: 0.9713\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0893 - accuracy: 0.9742 - val_loss: 0.0737 - val_accuracy: 0.9768\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0691 - accuracy: 0.9792 - val_loss: 0.0716 - val_accuracy: 0.9780\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.0735 - val_accuracy: 0.9787\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0464 - accuracy: 0.9863 - val_loss: 0.0637 - val_accuracy: 0.9811\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0369 - accuracy: 0.9886 - val_loss: 0.0684 - val_accuracy: 0.9816\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0737 - val_accuracy: 0.9818\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 0.0623 - val_accuracy: 0.9821\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.0796 - val_accuracy: 0.9827\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0795 - val_accuracy: 0.9819\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0805 - val_accuracy: 0.9805\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0892 - val_accuracy: 0.9819\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0805 - val_accuracy: 0.9820\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0897 - val_accuracy: 0.9809\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.1009 - val_accuracy: 0.9799\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0826 - val_accuracy: 0.9845\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0868 - val_accuracy: 0.9841\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0910 - val_accuracy: 0.9828\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1021 - val_accuracy: 0.9820\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1014 - val_accuracy: 0.9818\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.1050 - val_accuracy: 0.9838\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1038 - val_accuracy: 0.9828\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.1144 - val_accuracy: 0.9815\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1000 - val_accuracy: 0.9847\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1215 - val_accuracy: 0.9825\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.1139 - val_accuracy: 0.9853\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.1097 - val_accuracy: 0.9830\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1240 - val_accuracy: 0.9824\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1140 - val_accuracy: 0.9838\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.1394 - val_accuracy: 0.9824\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.1273 - val_accuracy: 0.9819\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1483 - val_accuracy: 0.9820\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.1325 - val_accuracy: 0.9833\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.1168 - val_accuracy: 0.9841\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1401 - val_accuracy: 0.9821\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.1361 - val_accuracy: 0.9819\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.1289 - val_accuracy: 0.9862\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1554 - val_accuracy: 0.9817\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.1493 - val_accuracy: 0.9820\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1561 - val_accuracy: 0.9808\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1479 - val_accuracy: 0.9831\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1394 - val_accuracy: 0.9836\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1365 - val_accuracy: 0.9846\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1531 - val_accuracy: 0.9824\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1405 - val_accuracy: 0.9829\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1401 - val_accuracy: 0.9838\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1439 - val_accuracy: 0.9849\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.1455 - val_accuracy: 0.9839\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1579 - val_accuracy: 0.9837\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1604 - val_accuracy: 0.9829\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1391 - val_accuracy: 0.9832\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1548 - val_accuracy: 0.9831\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.1768 - val_accuracy: 0.9820\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1669 - val_accuracy: 0.9832\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1569 - val_accuracy: 0.9833\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1773 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1409 - val_accuracy: 0.9839\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.1567 - val_accuracy: 0.9841\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1769 - val_accuracy: 0.9819\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.1760 - val_accuracy: 0.9824\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1514 - val_accuracy: 0.9829\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.1816 - val_accuracy: 0.9828\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1860 - val_accuracy: 0.9831\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1506 - val_accuracy: 0.9851\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1756 - val_accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.1858 - val_accuracy: 0.9832\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.1598 - val_accuracy: 0.9853\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1798 - val_accuracy: 0.9839\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.1699 - val_accuracy: 0.9837\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1883 - val_accuracy: 0.9825\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.1993 - val_accuracy: 0.9836\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.1941 - val_accuracy: 0.9817\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.2053 - val_accuracy: 0.9827\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1945 - val_accuracy: 0.9827\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.1820 - val_accuracy: 0.9836\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.2098 - val_accuracy: 0.9819\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.2099 - val_accuracy: 0.9806\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1929 - val_accuracy: 0.9827\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.2094 - val_accuracy: 0.9807\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.2056 - val_accuracy: 0.9824\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.2190 - val_accuracy: 0.9826\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1886 - val_accuracy: 0.9827\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1978 - val_accuracy: 0.9832\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.2208 - val_accuracy: 0.9810\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.1833 - val_accuracy: 0.9835\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.2115 - val_accuracy: 0.9828\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.2290 - val_accuracy: 0.9835\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.2160 - val_accuracy: 0.9823\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1964 - val_accuracy: 0.9834\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.2140 - val_accuracy: 0.9816\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.2254 - val_accuracy: 0.9832\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.1895 - val_accuracy: 0.9838\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.1850 - val_accuracy: 0.9827\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.2011 - val_accuracy: 0.9835\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.2323 - val_accuracy: 0.9832\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.2128 - val_accuracy: 0.9835\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.2143 - val_accuracy: 0.9843\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.2235 - val_accuracy: 0.9827\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.2362 - val_accuracy: 0.9824\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN=compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history=model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model Performance on the *Unseen* Test Data\n",
    "\n",
    "Next, we evaluate the model and read of the loss on the test data, and its accuracy using the `evaluate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9824\n",
      "\n",
      "Test loss: 0.23622189462184906\n",
      "Test accuracy: 0.9824000000953674\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Step 6: Modify the Hyperparameters to Optimize Performance of the Model\n",
    "\n",
    "Last, we show how to use the grid search option of scikit-learn to optimize the \n",
    "hyperparameters of our model. An excellent blog on this by Jason Brownlee can be found on [https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 2s 2ms/step - loss: 1.1169 - accuracy: 0.6698\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.8728\n",
      "704/704 [==============================] - 2s 2ms/step - loss: 1.1211 - accuracy: 0.6575\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.8695\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 1.1288 - accuracy: 0.6638\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.8690\n",
      "704/704 [==============================] - 2s 2ms/step - loss: 1.1736 - accuracy: 0.6517\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8851\n",
      "704/704 [==============================] - 3s 5ms/step - loss: 0.3377 - accuracy: 0.8992\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9584\n",
      "704/704 [==============================] - 3s 5ms/step - loss: 0.3433 - accuracy: 0.8994\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9596\n",
      "704/704 [==============================] - 3s 5ms/step - loss: 0.3373 - accuracy: 0.9014\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9544\n",
      "704/704 [==============================] - 3s 5ms/step - loss: 0.3465 - accuracy: 0.8991\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9575\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 1.7946 - accuracy: 0.4502\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.2049 - accuracy: 0.7718\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 1.7957 - accuracy: 0.4510\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.2276 - accuracy: 0.7909\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 1.7496 - accuracy: 0.4704\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1858 - accuracy: 0.7785\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 1.7846 - accuracy: 0.4486\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.1888 - accuracy: 0.7871\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 2.2988 - accuracy: 0.1224\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2.2083 - accuracy: 0.1776\n",
      "704/704 [==============================] - 3s 4ms/step - loss: 2.3437 - accuracy: 0.1206\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 2.2245 - accuracy: 0.1787\n",
      "704/704 [==============================] - 3s 5ms/step - loss: 2.3574 - accuracy: 0.1148\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 2.2668 - accuracy: 0.1577\n",
      "704/704 [==============================] - 3s 5ms/step - loss: 2.3299 - accuracy: 0.1181\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 2.2377 - accuracy: 0.1731\n",
      "704/704 [==============================] - 2s 4ms/step - loss: 0.3675 - accuracy: 0.8918\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9518\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.3624 - accuracy: 0.8920\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9571\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.3547 - accuracy: 0.8947\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9573\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.3492 - accuracy: 0.8970\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9609\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.5001 - accuracy: 0.8538\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9326\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.5133 - accuracy: 0.8507\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9341\n",
      "704/704 [==============================] - 3s 4ms/step - loss: 0.5087 - accuracy: 0.8534\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9268\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.4966 - accuracy: 0.8561\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9395\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.3469 - accuracy: 0.8973\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9574\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3608 - accuracy: 0.8948\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.95 - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9560\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3431 - accuracy: 0.8974\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9525\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3500 - accuracy: 0.8972\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9610\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.2950 - accuracy: 0.9135\n",
      "Best: 0.957483 using {'optimizer': 'RMSprop'}\n",
      "0.874117 (0.006525) with: {'optimizer': 'SGD'}\n",
      "0.957483 (0.001925) with: {'optimizer': 'RMSprop'}\n",
      "0.782067 (0.007450) with: {'optimizer': 'Adagrad'}\n",
      "0.171783 (0.008415) with: {'optimizer': 'Adadelta'}\n",
      "0.956767 (0.003236) with: {'optimizer': 'Adam'}\n",
      "0.933267 (0.004536) with: {'optimizer': 'Adamax'}\n",
      "0.956717 (0.003057) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# call Keras scikit wrapper\n",
    "model_gridsearch = KerasClassifier(build_fn=compile_model, \n",
    "                        epochs=1, \n",
    "                        batch_size=batch_size, \n",
    "                        verbose=1)\n",
    "\n",
    "# list of allowed optional arguments for the optimizer, see `compile_model()`\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# define parameter dictionary\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "# call scikit grid search module\n",
    "grid = GridSearchCV(estimator=model_gridsearch, param_grid=param_grid, n_jobs=1, cv=4)\n",
    "grid_result = grid.fit(X_train,Y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Convolutional Neural Nets with Keras\n",
    "\n",
    "We have so far considered each MNIST data sample as a $(28\\times 28,)$-long 1d vector. This approach neglects any spatial structure in the image. On the other hand, we do know that in every one of the hand-written digits there are *local* spatial correlations between the pixels, which we would like to take advantage of to improve the accuracy of our classification model. To this end, we first need to reshape the training and test input data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can ask the question of whether a neural net can learn to recognize such local patterns. As we saw in Sec. X of the review, this can be achieved by using convolutional layers. Luckily, all we need to do is change the architecture of our DNN, i.e. introduce small changes to the function `create_model()`. We can also merge **Step 2** and **Step 3** for convenience: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add second convolutional layer with 20 filters\n",
    "    model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # flatten data\n",
    "    model.add(Flatten())\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(20*4*4, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the deep conv net (**Step 4**) and evaluating its performance (**Step 6**) proceeds exactly as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.2584 - accuracy: 0.9183 - val_loss: 0.0778 - val_accuracy: 0.9817\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0976 - accuracy: 0.9702 - val_loss: 0.0575 - val_accuracy: 0.9865\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0753 - accuracy: 0.9767 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0632 - accuracy: 0.9802 - val_loss: 0.0488 - val_accuracy: 0.9879\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0388 - val_accuracy: 0.9917\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0506 - accuracy: 0.9844 - val_loss: 0.0348 - val_accuracy: 0.9897\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.0350 - val_accuracy: 0.9894\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 0.0274 - val_accuracy: 0.9918\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0433 - accuracy: 0.9862 - val_loss: 0.0288 - val_accuracy: 0.9919\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0377 - accuracy: 0.9882 - val_loss: 0.0259 - val_accuracy: 0.9924\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 0.0258 - val_accuracy: 0.9924\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0245 - val_accuracy: 0.9933\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0258 - val_accuracy: 0.9922\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.0245 - val_accuracy: 0.9923\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.0210 - val_accuracy: 0.9936\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.0251 - val_accuracy: 0.9927\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.0239 - val_accuracy: 0.9926\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0228 - val_accuracy: 0.9926\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.0228 - val_accuracy: 0.9932\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0239 - val_accuracy: 0.9927\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.0224 - val_accuracy: 0.9931\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.0220 - val_accuracy: 0.9926\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0214 - val_accuracy: 0.9937\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0212 - val_accuracy: 0.9929\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0225 - val_accuracy: 0.9929\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0219 - val_accuracy: 0.9934\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0211 - val_accuracy: 0.9932\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0214 - val_accuracy: 0.9939\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0215 - val_accuracy: 0.9934\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0208 - val_accuracy: 0.9941\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9941\n",
      "\n",
      "Test loss: 0.020819172263145447\n",
      "Test accuracy: 0.9940999746322632\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add second convolutional layer with 20 filters\n",
    "    model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # flatten data\n",
    "    model.add(Flatten())\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(20*4*4, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='RMSprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2586 - accuracy: 0.9189 - val_loss: 0.0839 - val_accuracy: 0.9794\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0960 - accuracy: 0.9704 - val_loss: 0.0533 - val_accuracy: 0.9841\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0754 - accuracy: 0.9771 - val_loss: 0.0436 - val_accuracy: 0.9872\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 0.0379 - val_accuracy: 0.9877\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0589 - accuracy: 0.9826 - val_loss: 0.0377 - val_accuracy: 0.9900\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0552 - accuracy: 0.9837 - val_loss: 0.0280 - val_accuracy: 0.9907\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0530 - accuracy: 0.9841 - val_loss: 0.0285 - val_accuracy: 0.9914\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0520 - accuracy: 0.9849 - val_loss: 0.0274 - val_accuracy: 0.9917\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0520 - accuracy: 0.9851 - val_loss: 0.0291 - val_accuracy: 0.9922\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.0301 - val_accuracy: 0.9904\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0537 - accuracy: 0.9847 - val_loss: 0.0422 - val_accuracy: 0.9867\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0541 - accuracy: 0.9852 - val_loss: 0.0333 - val_accuracy: 0.9902\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0533 - accuracy: 0.9846 - val_loss: 0.0290 - val_accuracy: 0.9906\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0560 - accuracy: 0.9850 - val_loss: 0.0322 - val_accuracy: 0.9908\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0577 - accuracy: 0.9839 - val_loss: 0.0400 - val_accuracy: 0.9894\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0573 - accuracy: 0.9848 - val_loss: 0.0439 - val_accuracy: 0.9884\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0586 - accuracy: 0.9842 - val_loss: 0.0325 - val_accuracy: 0.9892\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0600 - accuracy: 0.9837 - val_loss: 0.0398 - val_accuracy: 0.9883\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0599 - accuracy: 0.9845 - val_loss: 0.0346 - val_accuracy: 0.9909\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0641 - accuracy: 0.9835 - val_loss: 0.0390 - val_accuracy: 0.9897\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0638 - accuracy: 0.9838 - val_loss: 0.0396 - val_accuracy: 0.9891\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0625 - accuracy: 0.9832 - val_loss: 0.0309 - val_accuracy: 0.9910\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0678 - accuracy: 0.9824 - val_loss: 0.0374 - val_accuracy: 0.9893\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0672 - accuracy: 0.9826 - val_loss: 0.0544 - val_accuracy: 0.9875\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0712 - accuracy: 0.9826 - val_loss: 0.0513 - val_accuracy: 0.9844\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0717 - accuracy: 0.9817 - val_loss: 0.0878 - val_accuracy: 0.9783\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0741 - accuracy: 0.9821 - val_loss: 0.0734 - val_accuracy: 0.9813\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0699 - accuracy: 0.9825 - val_loss: 0.0400 - val_accuracy: 0.9886\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0723 - accuracy: 0.9826 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0743 - accuracy: 0.9820 - val_loss: 0.1757 - val_accuracy: 0.9661\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.9661\n",
      "\n",
      "Test loss: 0.17572152614593506\n",
      "Test accuracy: 0.9660999774932861\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have changed Epoch up to 100. The accuracy seems like is not increasing when it reaches 98.2%. Or maybe I would just need more values of Epcoh. From the hyperparameters to optimize performance of the model, I found Adam and RMSprop are the best optimizer, so I implement both solver with Epcoh = 30. Use Optimizer Adam gives me a 99.4% of accuracy, and Optimizer RMSprop gives me a 96.6% of accuracy. The optimized hyperparameter (Adam) did improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-85515e081ea7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-85515e081ea7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ADR: More discussion on what you learned (e.g. CNN or Keras) would be helpful. Wisdom? Take-away message. 1.75/2\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ADR: More discussion on what you learned (e.g. CNN or Keras) would be helpful. Wisdom? Take-away message. 1.75/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
